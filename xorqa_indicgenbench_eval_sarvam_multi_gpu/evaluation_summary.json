{
  "model_name": "sarvamai/sarvam-1",
  "dataset": "XOR-QA-IN",
  "num_samples_per_lang": 100,
  "languages_evaluated": 12,
  "overall_scores": {
    "xorqa_as": {
      "f1": 4.46971119766993,
      "exact_match": 0.0,
      "valid_samples": 75,
      "total_samples": 100
    },
    "xorqa_bn": {
      "f1": 16.044228915556094,
      "exact_match": 0.0,
      "valid_samples": 60,
      "total_samples": 100
    },
    "xorqa_gu": {
      "f1": 10.160280862628449,
      "exact_match": 0.0,
      "valid_samples": 89,
      "total_samples": 100
    },
    "xorqa_hi": {
      "f1": 13.029393771833785,
      "exact_match": 0.0,
      "valid_samples": 73,
      "total_samples": 100
    },
    "xorqa_kn": {
      "f1": 11.774246131399424,
      "exact_match": 0.0,
      "valid_samples": 83,
      "total_samples": 100
    },
    "xorqa_ml": {
      "f1": 11.890471193315525,
      "exact_match": 0.0,
      "valid_samples": 96,
      "total_samples": 100
    },
    "xorqa_mr": {
      "f1": 10.098464603009019,
      "exact_match": 0.0,
      "valid_samples": 82,
      "total_samples": 100
    },
    "xorqa_or": {
      "f1": 6.959963055322202,
      "exact_match": 0.0,
      "valid_samples": 92,
      "total_samples": 100
    },
    "xorqa_pa": {
      "f1": 10.831372627961343,
      "exact_match": 0.0,
      "valid_samples": 80,
      "total_samples": 100
    },
    "xorqa_ta": {
      "f1": 9.77767186960723,
      "exact_match": 0.0,
      "valid_samples": 82,
      "total_samples": 100
    },
    "xorqa_te": {
      "f1": 12.88306796781373,
      "exact_match": 0.0,
      "valid_samples": 59,
      "total_samples": 100
    },
    "xorqa_ur": {
      "f1": 0.31606990622335895,
      "exact_match": 0.0,
      "valid_samples": 100,
      "total_samples": 100
    }
  },
  "averages": {
    "f1": 9.852911841861674,
    "exact_match": 0.0
  }
}